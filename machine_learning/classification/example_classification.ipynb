{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instagram', 'owner', 'sticker', 'tiktok', 'twitter', 'youtube']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = os.listdir('./dataset')\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\word2vec\\\\model-64-32k-100k'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = os.path.join('..', 'word2vec', 'model-64-32k-100k')\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_ds = tf.data.TextLineDataset(os.path.join(MODEL_PATH, 'metadata.tsv')).filter(\n",
    "        # ignore [UNK] token\n",
    "        lambda text: tf.cast(not tf.strings.regex_full_match(text, '\\[UNK\\]'), bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 32000\n",
    "sequence_length = 64\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_sequence_length=sequence_length,\n",
    "        # add vocab\n",
    "        vocabulary=tf.constant(\n",
    "            [text.numpy() for text in vocab_ds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "Input: ubah foto tersebut menjadi stiker                                                           \n",
      "Prediction: [1.0709771e-04 1.2925623e-02 9.7308278e-01 8.7076845e-03 7.5087228e-05\n",
      " 5.1017310e-03]\n",
      "Predicted label: sticker : 0.9730828\n",
      "\n",
      "Input: download sebuah video dari youtube                                                           \n",
      "Prediction: [4.9528456e-03 6.3821142e-05 3.6024849e-04 7.8769969e-03 1.2307867e-04\n",
      " 9.8662311e-01]\n",
      "Predicted label: youtube : 0.9866231\n",
      "\n",
      "Input: bisakah kamu mengubah foto di atas menjadi [UNK]                                                        \n",
      "Prediction: [0.00121241 0.12463619 0.81722116 0.01944517 0.00110361 0.0363814 ]\n",
      "Predicted label: sticker : 0.81722116\n",
      "\n",
      "Input: [UNK] saya berbicara dengan owner anda untuk meminta bantuan                                                       \n",
      "Prediction: [2.7026160e-04 9.9885869e-01 3.8257951e-04 2.7746297e-05 4.2576852e-04\n",
      " 3.4977402e-05]\n",
      "Predicted label: owner : 0.9988587\n",
      "\n",
      "Input: download video dari instagram                                                            \n",
      "Prediction: [9.5791948e-01 3.5529286e-03 1.9181908e-04 7.7588740e-03 1.6475094e-02\n",
      " 1.4101723e-02]\n",
      "Predicted label: instagram : 0.9579195\n",
      "\n",
      "Input: [UNK] saya sebuah video dari tiktok                                                          \n",
      "Prediction: [3.4549733e-04 2.2254296e-06 2.2387342e-03 9.9591100e-01 7.2996807e-04\n",
      " 7.7254261e-04]\n",
      "Predicted label: tiktok : 0.995911\n",
      "\n",
      "Input: saya mempunyai link video twitter download video twitter tersebut                                                       \n",
      "Prediction: [3.9494282e-04 1.8074859e-05 1.8791733e-06 8.5017213e-04 9.9873477e-01\n",
      " 7.8391615e-08]\n",
      "Predicted label: twitter : 0.9987348\n",
      "\n",
      "Input: buat stiker                                                              \n",
      "Prediction: [0.00509787 0.07469838 0.78725886 0.05692878 0.00325452 0.07276161]\n",
      "Predicted label: sticker : 0.78725886\n",
      "\n",
      "Input: halo bagaimana kabar kamu                                                            \n",
      "Prediction: [0.12154441 0.3317244  0.06050636 0.0880342  0.37488493 0.02330566]\n",
      "Predicted label: twitter : 0.37488493\n",
      "\n",
      "Input: makan ayam goreng                                                             \n",
      "Prediction: [0.0288954  0.13036965 0.48751613 0.12411982 0.01898398 0.21011508]\n",
      "Predicted label: sticker : 0.48751613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = [\n",
    "    \"ubah foto tersebut menjadi stiker\",\n",
    "    \"download sebuah video dari youtube\",\n",
    "    \"bisakah kamu mengubah foto di atas menjadi sticker?\",\n",
    "    \"dapatkah saya berbicara dengan owner anda untuk meminta bantuan?\",\n",
    "    \"download video dari instagram\",\n",
    "    \"unduhkan saya sebuah video dari tiktok\",\n",
    "    \"saya mempunyai link video twitter, download video twitter tersebut\",\n",
    "    \"buat stiker\",\n",
    "    \"halo bagaimana kabar kamu?\",\n",
    "    \"makan ayam goreng\"\n",
    "]\n",
    "example = tf.constant([vectorize_layer(text).numpy() for text in example])\n",
    "\n",
    "predicted = model.predict(example)\n",
    "\n",
    "for pred in predicted:\n",
    "    index = predicted.tolist().index(pred.tolist())\n",
    "    score = max(pred)\n",
    "    higest_index = pred.tolist().index(score)\n",
    "    print(\"Input:\", \" \".join([vocab[each] for each in example[index].numpy()]))\n",
    "    print(\"Prediction:\", pred)\n",
    "    print(\"Predicted label:\", class_name[higest_index], \":\", score)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
